# Numerical Implementation

**DocumentaciÃ³n tÃ©cnica interna de la implementaciÃ³n de mÃ©todos numÃ©ricos.**

## ğŸ›ï¸ Arquitectura del sistema

### Flujo de datos

```
Usuario SOC:  diff(f, 2.0)
      â†“
achronyme-eval: handlers::numerical::handle_diff()
      â†“
achronyme-numerical: diff_central(&mut evaluator, &func, x, h)
      â†“
LambdaEvaluator trait: evaluator.eval_at(func, x + h)
      â†“
Evaluator: EvalÃºa func(x + h) â†’ f64
      â†“
Resultado: f'(x) â‰ˆ (f(x+h) - f(x-h)) / 2h
```

### SeparaciÃ³n de responsabilidades

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  achronyme-numerical (ESTE CRATE)                       â”‚
â”‚  â”œâ”€â”€ differentiation.rs                                 â”‚
â”‚  â”‚   â””â”€â”€ Algoritmos de diferencias finitas             â”‚
â”‚  â”œâ”€â”€ integration.rs                                     â”‚
â”‚  â”‚   â””â”€â”€ Algoritmos de cuadratura                      â”‚
â”‚  â””â”€â”€ solvers.rs                                         â”‚
â”‚      â””â”€â”€ Algoritmos de bÃºsqueda de raÃ­ces              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†‘
                         â”‚ usa
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  achronyme-types                                        â”‚
â”‚  â”œâ”€â”€ Function (representaciÃ³n de funciones)            â”‚
â”‚  â””â”€â”€ LambdaEvaluator trait (evaluar funciones)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura de mÃ³dulos

```
src/
â”œâ”€â”€ lib.rs                    # Re-exports pÃºblicos
â”œâ”€â”€ differentiation.rs        # 218 LOC - Diferencias finitas
â”œâ”€â”€ integration.rs            # 349 LOC - Cuadratura numÃ©rica
â””â”€â”€ solvers.rs                # 326 LOC - Root finding

Total: ~900 LOC
```

### lib.rs - API pÃºblica

```rust
pub mod differentiation;
pub mod integration;
pub mod solvers;

// Re-exports para conveniencia
pub use differentiation::*;
pub use integration::*;
pub use solvers::*;
```

**Responsabilidades**:
- Organizar mÃ³dulos
- Re-exportar funciones pÃºblicas
- DocumentaciÃ³n a nivel de crate

## ğŸ” MÃ³dulo: differentiation.rs

### Funciones implementadas

| FunciÃ³n | Firma | Complejidad | PrecisiÃ³n |
|---------|-------|-------------|-----------|
| `diff_forward` | `<F: FnMut(f64) -> f64>` | O(1) | O(h) |
| `diff_backward` | `<F: FnMut(f64) -> f64>` | O(1) | O(h) |
| `diff_central` | `<E: LambdaEvaluator>` | O(1) | O(hÂ²) |
| `diff2_central` | `<E: LambdaEvaluator>` | O(1) | O(hÂ²) |
| `diff3_central` | `<E: LambdaEvaluator>` | O(1) | O(hÂ²) |
| `gradient` | `<E: LambdaEvaluator>` | O(n) | O(hÂ²) |

### ImplementaciÃ³n de diff_central

```rust
pub fn diff_central<E>(
    evaluator: &mut E,
    func: &Function,
    x: f64,
    h: f64,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    // Evaluar f(x + h)
    let f_plus = evaluator.eval_at(func, x + h)?;

    // Evaluar f(x - h)
    let f_minus = evaluator.eval_at(func, x - h)?;

    // f'(x) â‰ˆ (f(x+h) - f(x-h)) / 2h
    Ok((f_plus - f_minus) / (2.0 * h))
}
```

**Detalles tÃ©cnicos**:
1. **SeparaciÃ³n de evaluaciones**: No evalÃºa f(x) directamente (no se necesita)
2. **PropagaciÃ³n de errores**: Usa `?` para propagar errores de evaluaciÃ³n
3. **No assumptions**: No asume nada sobre la funciÃ³n (puede ser no lineal)
4. **Step size h**: Caller decide h (tÃ­picamente 1e-5)

### ImplementaciÃ³n de gradient

```rust
pub fn gradient<E>(
    evaluator: &mut E,
    func: &Function,
    point: &[f64],
    h: f64,
) -> Result<Vec<f64>, String>
where
    E: LambdaEvaluator,
{
    let n = point.len();
    let mut grad = vec![0.0; n];

    for i in 0..n {
        // Crear point_plus y point_minus
        let mut point_plus = point.to_vec();
        let mut point_minus = point.to_vec();

        point_plus[i] += h;
        point_minus[i] -= h;

        // Evaluar en ambos puntos
        let f_plus = evaluator.eval_vec_at(func, &point_plus)?;
        let f_minus = evaluator.eval_vec_at(func, &point_minus)?;

        // âˆ‚f/âˆ‚x_i â‰ˆ (f(..., x_i + h, ...) - f(..., x_i - h, ...)) / 2h
        grad[i] = (f_plus - f_minus) / (2.0 * h);
    }

    Ok(grad)
}
```

**CaracterÃ­sticas**:
- **Costo**: 2n evaluaciones de funciÃ³n (eficiente)
- **Uso de memoria**: O(n) para almacenar gradiente
- **Paralelizable**: Cada componente es independiente (no implementado aÃºn)

### API antigua vs nueva

**Antigua** (closures):
```rust
pub fn diff_forward<F>(mut f: F, x: f64, h: f64) -> f64
where
    F: FnMut(f64) -> f64,
{
    (f(x + h) - f(x)) / h
}
```

**Nueva** (LambdaEvaluator):
```rust
pub fn diff_central<E>(
    evaluator: &mut E,
    func: &Function,
    x: f64,
    h: f64,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    let f_plus = evaluator.eval_at(func, x + h)?;
    let f_minus = evaluator.eval_at(func, x - h)?;
    Ok((f_plus - f_minus) / (2.0 * h))
}
```

**Ventajas de la nueva API**:
- âœ… IntegraciÃ³n con sistema de tipos de Achronyme
- âœ… Manejo de errores robusto (`Result<f64, String>`)
- âœ… Soporta funciones SOC user-defined
- âœ… Permite evaluaciÃ³n en entorno con variables

## ğŸ” MÃ³dulo: integration.rs

### Funciones implementadas

| FunciÃ³n | Subdivisions | PrecisiÃ³n | Adaptativo | Uso |
|---------|--------------|-----------|------------|-----|
| `trapz` | n fijo | O(nâ»Â²) | No | General, rÃ¡pido |
| `simpson` | n fijo (par) | O(nâ»â´) | No | MÃ¡s preciso |
| `simpson38` | n fijo (Ã—3) | O(nâ»â´) | No | Alternativa |
| `romberg` | 2^k | Exponencial | SÃ­ | Alta precisiÃ³n |
| `quad` | Adaptativo | SegÃºn tol | SÃ­ | Balance |
| `trapz_discrete` | - | - | No | Datos tabulados |

### ImplementaciÃ³n de trapz

```rust
pub fn trapz<E>(
    evaluator: &mut E,
    func: &Function,
    a: f64,
    b: f64,
    n: usize,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    if n == 0 {
        return Ok(0.0);
    }

    let h = (b - a) / n as f64;

    // Evaluar extremos
    let f_a = evaluator.eval_at(func, a)?;
    let f_b = evaluator.eval_at(func, b)?;

    // Suma ponderada: 0.5 * (f(a) + f(b))
    let mut sum = 0.5 * (f_a + f_b);

    // Sumar puntos interiores con peso 1.0
    for i in 1..n {
        sum += evaluator.eval_at(func, a + i as f64 * h)?;
    }

    Ok(h * sum)
}
```

**CaracterÃ­sticas**:
- **Evaluaciones**: n + 1 evaluaciones de funciÃ³n
- **Estabilidad**: Acumula suma (puede tener error de redondeo)
- **Mejora**: Compensated summation (Kahan) para mayor precisiÃ³n (no implementado)

### ImplementaciÃ³n de simpson

```rust
pub fn simpson<E>(
    evaluator: &mut E,
    func: &Function,
    a: f64,
    b: f64,
    n: usize,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    // Asegurar n par
    let n = if n % 2 == 0 { n } else { n + 1 };

    if n == 0 {
        return Ok(0.0);
    }

    let h = (b - a) / n as f64;

    let f_a = evaluator.eval_at(func, a)?;
    let f_b = evaluator.eval_at(func, b)?;
    let mut sum = f_a + f_b;

    // PatrÃ³n 4-2-4-2-... (alternar pesos)
    for i in 1..n {
        let x = a + i as f64 * h;
        let coefficient = if i % 2 == 0 { 2.0 } else { 4.0 };
        sum += coefficient * evaluator.eval_at(func, x)?;
    }

    Ok((h / 3.0) * sum)
}
```

**PatrÃ³n de pesos**:
```
i:     0   1   2   3   4   5   ...  n
peso:  1   4   2   4   2   4   ...  1
```

**Por quÃ© es mÃ¡s preciso**:
- Trapz usa interpolaciÃ³n lineal (rectas)
- Simpson usa interpolaciÃ³n cuadrÃ¡tica (parÃ¡bolas)
- Exacto para polinomios de grado â‰¤ 3

### ImplementaciÃ³n de Romberg

```rust
pub fn romberg<E>(
    evaluator: &mut E,
    func: &Function,
    a: f64,
    b: f64,
    tol: f64,
    max_iter: usize,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    let mut r = vec![vec![0.0; max_iter]; max_iter];

    // Columna 0: Regla del trapecio con 1, 2, 4, 8, ... subdivisiones
    let f_a = evaluator.eval_at(func, a)?;
    let f_b = evaluator.eval_at(func, b)?;
    r[0][0] = (b - a) * (f_a + f_b) / 2.0;

    for i in 1..max_iter {
        let n = 1 << i; // 2^i
        let h = (b - a) / n as f64;

        // Trapecio compuesto (solo evaluar nuevos puntos)
        let mut sum = 0.0;
        for j in 1..n {
            if j % 2 == 1 {
                sum += evaluator.eval_at(func, a + j as f64 * h)?;
            }
        }

        r[i][0] = 0.5 * r[i - 1][0] + h * sum;

        // ExtrapolaciÃ³n de Richardson
        for j in 1..=i {
            let power = 4_f64.powi(j as i32);
            r[i][j] = (power * r[i][j - 1] - r[i - 1][j - 1]) / (power - 1.0);
        }

        // Verificar convergencia
        if i > 0 && (r[i][i] - r[i - 1][i - 1]).abs() < tol {
            return Ok(r[i][i]);
        }
    }

    Ok(r[max_iter - 1][max_iter - 1])
}
```

**Tabla de Romberg** (ejemplo):
```
       j=0         j=1         j=2         j=3
i=0   R[0,0]
i=1   R[1,0]     R[1,1]
i=2   R[2,0]     R[2,1]     R[2,2]
i=3   R[3,0]     R[3,1]     R[3,2]     R[3,3]
```

**FÃ³rmula de Richardson**:
```
R[i,j] = (4^j * R[i,j-1] - R[i-1,j-1]) / (4^j - 1)
```

**Ventaja**: Cada columna a la derecha duplica el orden de precisiÃ³n.

### ImplementaciÃ³n de trapz_discrete

```rust
pub fn trapz_discrete(x: &[f64], y: &[f64]) -> f64 {
    if x.len() != y.len() || x.len() < 2 {
        return 0.0;
    }

    let mut sum = 0.0;

    for i in 0..x.len() - 1 {
        let h = x[i + 1] - x[i];
        sum += 0.5 * h * (y[i] + y[i + 1]);
    }

    sum
}
```

**Uso**: Cuando tienes datos experimentales en lugar de una funciÃ³n analÃ­tica.

**Ejemplo**:
```rust
let x = vec![0.0, 0.5, 1.0, 1.5, 2.0];
let y = vec![0.0, 0.25, 1.0, 2.25, 4.0]; // y = xÂ²
let area = trapz_discrete(&x, &y); // â‰ˆ 2.67 (exacto: 8/3)
```

## ğŸ” MÃ³dulo: solvers.rs

### Funciones implementadas

| FunciÃ³n | Convergencia | Requisitos | Complejidad | Uso |
|---------|--------------|------------|-------------|-----|
| `bisect` | Lineal | f(a)Â·f(b) < 0 | O(log Îµâ»Â¹) | Robusto |
| `newton` | CuadrÃ¡tica | f, f' | O(log log Îµâ»Â¹) | RÃ¡pido |
| `secant` | Superlineal | f | O(k log Îµâ»Â¹) | Balance |
| `fixed_point_iteration` | Lineal | \|g'(x)\| < 1 | O(Îµâ»Â¹) | Simple |
| `newton_system_2d` | CuadrÃ¡tica | f1, f2 | O(k) | Sistemas |

### ImplementaciÃ³n de bisect

```rust
pub fn bisect<E>(
    evaluator: &mut E,
    func: &Function,
    mut a: f64,
    mut b: f64,
    tol: f64,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    let fa = evaluator.eval_at(func, a)?;
    let fb = evaluator.eval_at(func, b)?;

    // Verificar teorema del valor intermedio
    if fa * fb > 0.0 {
        return Err("bisect: f(a) and f(b) must have opposite signs".to_string());
    }

    // Iterar hasta convergencia
    while (b - a).abs() > tol {
        let c = (a + b) / 2.0;
        let fc = evaluator.eval_at(func, c)?;

        // Si f(c) â‰ˆ 0, hemos encontrado la raÃ­z
        if fc.abs() < tol {
            return Ok(c);
        }

        // Actualizar intervalo
        if fa * fc < 0.0 {
            b = c;
        } else {
            a = c;
        }
    }

    Ok((a + b) / 2.0)
}
```

**Invariante**: f(a) Â· f(b) < 0 (signos opuestos) en cada iteraciÃ³n.

**Convergencia**:
```
IteraciÃ³n k: error â‰¤ (bâ‚€ - aâ‚€) / 2^k
```

Para Îµ = 1e-6, bâ‚€ - aâ‚€ = 10:
```
k = logâ‚‚(10 / 1e-6) = logâ‚‚(10^7) â‰ˆ 23 iteraciones
```

### ImplementaciÃ³n de newton

```rust
pub fn newton<E>(
    evaluator: &mut E,
    func: &Function,
    dfunc: &Function,
    mut x: f64,
    tol: f64,
    max_iter: usize,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    for _ in 0..max_iter {
        let fx = evaluator.eval_at(func, x)?;

        // Verificar convergencia
        if fx.abs() < tol {
            return Ok(x);
        }

        let dfx = evaluator.eval_at(dfunc, x)?;

        // Evitar divisiÃ³n por cero
        if dfx.abs() < 1e-12 {
            return Err("Newton: derivative too small, cannot continue".to_string());
        }

        // x_{n+1} = x_n - f(x_n) / f'(x_n)
        x = x - fx / dfx;
    }

    Ok(x)
}
```

**Convergencia cuadrÃ¡tica**:
```
|e_{n+1}| â‰¤ C|e_n|Â²

Ejemplo: error = 0.1
Iter 1: 0.01
Iter 2: 0.0001
Iter 3: 0.00000001  (8 dÃ­gitos de precisiÃ³n en 3 iteraciones!)
```

**Problema**: Puede divergir si el punto inicial estÃ¡ lejos de la raÃ­z.

### ImplementaciÃ³n de secant

```rust
pub fn secant<E>(
    evaluator: &mut E,
    func: &Function,
    mut x0: f64,
    mut x1: f64,
    tol: f64,
    max_iter: usize,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    let mut fx0 = evaluator.eval_at(func, x0)?;

    for _ in 0..max_iter {
        let fx1 = evaluator.eval_at(func, x1)?;

        if fx1.abs() < tol {
            return Ok(x1);
        }

        // Evitar divisiÃ³n por cero
        if (fx1 - fx0).abs() < 1e-12 {
            return Err("Secant: denominator too small, cannot continue".to_string());
        }

        // x_{n+1} = x_n - f(x_n) * (x_n - x_{n-1}) / (f(x_n) - f(x_{n-1}))
        let x2 = x1 - fx1 * (x1 - x0) / (fx1 - fx0);

        // Actualizar para prÃ³xima iteraciÃ³n
        x0 = x1;
        fx0 = fx1;
        x1 = x2;
    }

    Ok(x1)
}
```

**Ventaja sobre Newton**:
- No requiere calcular f'(x) (ahorro de 1 evaluaciÃ³n por iteraciÃ³n)
- Aproxima f'(x) con diferencias finitas usando dos puntos

**Convergencia**:
```
|e_{n+1}| â‰ˆ |e_n|^Ï†  donde Ï† = (1 + âˆš5) / 2 â‰ˆ 1.618 (golden ratio)
```

MÃ¡s lento que Newton pero mÃ¡s rÃ¡pido que bisecciÃ³n.

### ImplementaciÃ³n de newton_system_2d

```rust
pub fn newton_system_2d<F1, F2>(
    mut f1: F1,
    mut f2: F2,
    mut x: f64,
    mut y: f64,
    tol: f64,
    max_iter: usize,
) -> (f64, f64)
where
    F1: FnMut(f64, f64) -> f64,
    F2: FnMut(f64, f64) -> f64,
{
    let h = 1e-8;

    for _ in 0..max_iter {
        let f1_val = f1(x, y);
        let f2_val = f2(x, y);

        // Verificar convergencia
        if f1_val.abs() < tol && f2_val.abs() < tol {
            return (x, y);
        }

        // Jacobiano (diferencias finitas)
        let df1_dx = (f1(x + h, y) - f1_val) / h;
        let df1_dy = (f1(x, y + h) - f1_val) / h;
        let df2_dx = (f2(x + h, y) - f2_val) / h;
        let df2_dy = (f2(x, y + h) - f2_val) / h;

        // Determinante del Jacobiano
        let det = df1_dx * df2_dy - df1_dy * df2_dx;

        if det.abs() < 1e-12 {
            break; // Jacobiano singular
        }

        // Resolver J Â· [dx, dy]^T = -[f1, f2]^T usando regla de Cramer
        let dx = (-f1_val * df2_dy + f2_val * df1_dy) / det;
        let dy = (f1_val * df2_dx - f2_val * df1_dx) / det;

        // Actualizar
        x += dx;
        y += dy;
    }

    (x, y)
}
```

**Jacobiano** para sistema 2D:
```
J = | âˆ‚f1/âˆ‚x  âˆ‚f1/âˆ‚y |
    | âˆ‚f2/âˆ‚x  âˆ‚f2/âˆ‚y |
```

**IteraciÃ³n de Newton**:
```
[x]     [x]       -1  [f1(x,y)]
[y]   = [y]  - J      [f2(x,y)]
 n+1     n
```

**Ejemplo**: Encontrar intersecciÃ³n de cÃ­rculo y recta:
```
f1(x, y) = xÂ² + yÂ² - 25  (cÃ­rculo de radio 5)
f2(x, y) = x - y - 1      (recta y = x - 1)

Soluciones: (4, 3) y (-3, -4)
```

## ğŸ§ª Testing

### Estado actual de los tests

**Problema**: Tests marcados como `#[ignore]` porque:
```rust
// API antigua (closures)
let f = |x: f64| x * x;
let derivative = diff_forward(f, 2.0, 1e-5);
```

**Necesitan refactoring a**:
```rust
// API nueva (LambdaEvaluator)
let mut evaluator = Evaluator::new();
let func = parse_to_function("x => x * x")?;
let derivative = diff_central(&mut evaluator, &func, 2.0, 1e-5)?;
```

### Tests pendientes

```rust
// differentiation.rs
#[test]
#[ignore]
fn test_forward_difference() { /* TODO */ }

#[test]
#[ignore]
fn test_central_difference() { /* TODO */ }

#[test]
#[ignore]
fn test_gradient() { /* TODO */ }

// integration.rs
#[test]
#[ignore]
fn test_trapz_linear() { /* TODO */ }

#[test]
#[ignore]
fn test_simpson_quadratic() { /* TODO */ }

#[test]
#[ignore]
fn test_romberg() { /* TODO */ }

// solvers.rs
#[test]
#[ignore]
fn test_bisect_quadratic() { /* TODO */ }

#[test]
#[ignore]
fn test_newton_quadratic() { /* TODO */ }

#[test]
#[ignore]
fn test_secant() { /* TODO */ }
```

### Test de trapz_discrete (Ãºnico que funciona)

```rust
#[test]
fn test_trapz_discrete() {
    let x = vec![0.0, 0.5, 1.0];
    let y = vec![0.0, 0.25, 1.0];  // y = xÂ²
    let result = trapz_discrete(&x, &y);
    // âˆ«â‚€Â¹ xÂ² dx = 1/3 â‰ˆ 0.333
    assert!((result - 1.0 / 3.0).abs() < 0.05);
}
```

## ğŸ“ Patrones de diseÃ±o

### 1. Trait-based API

Todas las funciones usan genÃ©ricos con trait bound:
```rust
pub fn diff_central<E>(
    evaluator: &mut E,
    func: &Function,
    x: f64,
    h: f64,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    // ...
}
```

**Ventajas**:
- âœ… Flexible: Cualquier tipo que implemente `LambdaEvaluator` funciona
- âœ… Testeable: Puede usar mock evaluator en tests
- âœ… Sin overhead: Monomorphization elimina costo de abstracciÃ³n

### 2. Error propagation with Result

```rust
let f_plus = evaluator.eval_at(func, x + h)?;
```

Propaga errores de evaluaciÃ³n al caller:
- DivisiÃ³n por cero
- Dominio invÃ¡lido (ej: sqrt(-1))
- Stack overflow en recursiÃ³n

### 3. Numerical stability checks

```rust
if dfx.abs() < 1e-12 {
    return Err("Newton: derivative too small, cannot continue".to_string());
}
```

Evita:
- DivisiÃ³n por cero
- Overflow/underflow
- CancelaciÃ³n catastrÃ³fica

### 4. Early return on convergence

```rust
if fx.abs() < tol {
    return Ok(x);
}
```

Ahorra iteraciones innecesarias cuando ya convergiÃ³.

## ğŸ”§ ExtensiÃ³n y mantenimiento

### Agregar nuevo mÃ©todo de integraciÃ³n

**Ejemplo**: Gauss-Legendre quadrature

1. **Implementar en `integration.rs`**:
```rust
/// Gauss-Legendre quadrature (n-point)
///
/// Exacto para polinomios de grado â‰¤ 2n-1
pub fn gauss_legendre<E>(
    evaluator: &mut E,
    func: &Function,
    a: f64,
    b: f64,
    n: usize,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    // Tabla de nodos y pesos pre-calculados
    let (nodes, weights) = match n {
        2 => (vec![-0.5773502691896257, 0.5773502691896257],
              vec![1.0, 1.0]),
        3 => (vec![-0.7745966692414834, 0.0, 0.7745966692414834],
              vec![0.5555555555555556, 0.8888888888888888, 0.5555555555555556]),
        // ... mÃ¡s puntos
        _ => return Err("Gauss-Legendre: unsupported number of points".to_string()),
    };

    // Transformar de [-1, 1] a [a, b]
    let mid = (a + b) / 2.0;
    let half = (b - a) / 2.0;

    let mut sum = 0.0;
    for i in 0..n {
        let x = mid + half * nodes[i];
        sum += weights[i] * evaluator.eval_at(func, x)?;
    }

    Ok(half * sum)
}
```

2. **Re-exportar en `lib.rs`**:
```rust
pub use integration::gauss_legendre;
```

3. **Agregar test**:
```rust
#[test]
fn test_gauss_legendre_polynomial() {
    // Exacto para polinomios grado â‰¤ 2n-1
    // âˆ«â‚€Â¹ xâ´ dx = 1/5 con n=3 puntos (grado 5)
}
```

### Agregar mÃ©todo de raÃ­ces (Brent)

**Brent's method**: Combina bisecciÃ³n, secant e interpolaciÃ³n cuadrÃ¡tica

```rust
pub fn brent<E>(
    evaluator: &mut E,
    func: &Function,
    mut a: f64,
    mut b: f64,
    tol: f64,
) -> Result<f64, String>
where
    E: LambdaEvaluator,
{
    // 1. Verificar f(a) * f(b) < 0
    // 2. Iterar:
    //    - Intentar interpolaciÃ³n cuadrÃ¡tica inversa
    //    - Si falla, usar secant
    //    - Si secant diverge, usar bisecciÃ³n
    // 3. Retornar cuando |b - a| < tol
}
```

## ğŸ“Š Complejidad y rendimiento

### Evaluaciones de funciÃ³n por mÃ©todo

| OperaciÃ³n | Evaluaciones | Notas |
|-----------|--------------|-------|
| diff_central(f, x) | 2 | f(x+h), f(x-h) |
| diff2_central(f, x) | 3 | f(x+h), f(x), f(x-h) |
| gradient(f, p) | 2n | n dimensiones |
| trapz(f, a, b, n) | n+1 | Todos los puntos |
| simpson(f, a, b, n) | n+1 | Todos los puntos |
| romberg(f, a, b) | ~2^k | Adaptativo, k iteraciones |
| bisect(f, a, b) | logâ‚‚(L/Îµ) | L = b-a, Îµ = tolerancia |
| newton(f, df, xâ‚€) | 2k | k iteraciones, f y f' cada vez |
| secant(f, xâ‚€, xâ‚) | k+1 | k iteraciones, solo f |

### Optimizaciones posibles

1. **Memoization**: Cache evaluaciones repetidas
   ```rust
   let mut cache = HashMap::new();
   if let Some(&val) = cache.get(&x) {
       return val;
   }
   ```

2. **Parallel gradient**: Evaluar âˆ‚f/âˆ‚xáµ¢ en paralelo
   ```rust
   use rayon::prelude::*;
   let grad: Vec<f64> = (0..n).into_par_iter()
       .map(|i| compute_partial_derivative(i))
       .collect();
   ```

3. **Adaptive step size**: Ajustar h segÃºn magnitud de f
   ```rust
   let h = h_base * (1.0 + f_val.abs()).sqrt();
   ```

4. **Richardson extrapolation**: Mejorar precisiÃ³n usando mÃºltiples h
   ```rust
   let d1 = diff_central(f, x, h);
   let d2 = diff_central(f, x, h/2);
   let improved = (4.0 * d2 - d1) / 3.0; // O(hâ´) precisiÃ³n
   ```

## ğŸ¯ Casos especiales y limitaciones

### DiferenciaciÃ³n

**Problemas**:
- **h muy pequeÃ±o**: Error de redondeo domina
- **h muy grande**: Error de truncamiento domina
- **Funciones discontinuas**: No funciona

**SoluciÃ³n**:
```rust
// Elegir h adaptativo
let h = if x.abs() > 1.0 {
    1e-5 * x.abs() // Proporcional a magnitud de x
} else {
    1e-5
};
```

### IntegraciÃ³n

**Problemas**:
- **Funciones oscilatorias**: Requieren muchas subdivisiones
- **Singularidades**: Integral diverge o requiere tratamiento especial
- **Intervalos infinitos**: Requieren cambio de variable

**Ejemplo**: âˆ«â‚€^âˆ eâ»Ë£ dx
```rust
// Cambio de variable: x = t/(1-t), dx = dt/(1-t)Â²
// âˆ«â‚€^âˆ eâ»Ë£ dx = âˆ«â‚€Â¹ eâ»áµ—â„â½Â¹â»áµ—â¾ / (1-t)Â² dt
```

### ResoluciÃ³n de raÃ­ces

**Problemas**:
- **RaÃ­ces mÃºltiples**: Convergencia lenta
- **MÃºltiples raÃ­ces**: Solo encuentra una
- **Sin raÃ­z**: BisecciÃ³n falla si f(a)Â·f(b) > 0

**Estrategias**:
- Usar deflaciÃ³n para encontrar mÃºltiples raÃ­ces
- Dividir dominio y buscar en cada intervalo
- Combinar mÃ©todos (Brent = bisecciÃ³n + secant + inversa cuadrÃ¡tica)

## ğŸ”— IntegraciÃ³n con achronyme-eval

### Flujo completo: Usuario â†’ Resultado

1. **Usuario escribe SOC**:
   ```javascript
   let f = x => x^2 - 4
   solve(f, 0, 5)
   ```

2. **Parser genera AST**:
   ```rust
   AstNode::FunctionCall {
       name: "solve",
       args: vec![
           AstNode::Lambda { ... },
           AstNode::Number(0.0),
           AstNode::Number(5.0)
       ]
   }
   ```

3. **Evaluador despacha a handler**:
   ```rust
   // achronyme-eval/src/handlers/numerical.rs
   "solve" => {
       let func = eval_to_function(args[0])?;
       let a = eval_to_f64(args[1])?;
       let b = eval_to_f64(args[2])?;

       let root = bisect(evaluator, &func, a, b, 1e-6)?;
       Ok(Value::Number(root))
   }
   ```

4. **Numerical crate ejecuta algoritmo**:
   ```rust
   // achronyme-numerical/src/solvers.rs
   pub fn bisect<E>(evaluator, func, a, b, tol) {
       // ... algoritmo de bisecciÃ³n
       Ok((a + b) / 2.0)
   }
   ```

5. **Resultado retorna al usuario**:
   ```
   2.0
   ```

## ğŸ“š Referencias

### Libros
- **Burden & Faires** (2010). *Numerical Analysis*. Brooks/Cole.
- **Press et al.** (2007). *Numerical Recipes: The Art of Scientific Computing*. Cambridge.
- **Heath** (2018). *Scientific Computing: An Introductory Survey*. SIAM.

### Papers
- **Richardson** (1911). "The Approximate Arithmetical Solution by Finite Differences of Physical Problems Involving Differential Equations."
- **Romberg** (1955). "Vereinfachte numerische Integration."
- **Brent** (1973). "An algorithm with guaranteed convergence for finding a zero of a function."

### Online
- [Numerical Methods - MIT OpenCourseWare](https://ocw.mit.edu)
- [GSL Manual](https://www.gnu.org/software/gsl/doc/html/index.html)
- [SciPy Documentation](https://docs.scipy.org/doc/scipy/reference/integrate.html)
