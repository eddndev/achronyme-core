# achronyme-linalg

Advanced Linear Algebra module for Achronyme.

## ğŸ¯ Responsibility

The `achronyme-linalg` crate provides comprehensive linear algebra operations for the Achronyme language, including:

- **Matrix Decompositions**: LU, QR, Cholesky, and SVD (Singular Value Decomposition)
- **Eigenvalue Computations**: Eigenvalues, eigenvectors, and specialized algorithms (Power Iteration, QR Algorithm)
- **Linear System Solvers**: Direct solution methods, matrix inversion, determinant computation
- **Matrix Analysis**: Symmetry checking, positive-definiteness testing

This crate serves as the numerical linear algebra backend for Achronyme, powered by the high-performance **faer** library (100% Rust, WASM-compatible). It bridges the gap between Achronyme's tensor types and advanced matrix operations required for scientific computing, optimization, and machine learning applications.

## ğŸ“¦ Dependencies

### External Crates
- **faer** (v0.19): Modern, high-performance linear algebra library written in 100% Rust
  - WASM-compatible (no C/Fortran dependencies)
  - Excellent performance rivaling LAPACK/BLAS
  - Safe, memory-efficient implementations
- **num-traits** (v0.2): Generic numeric traits for abstraction
- **num-complex** (v0.4): Complex number arithmetic
- **approx** (v0.5, dev): Floating-point comparison utilities for tests

### Internal Crates
- **achronyme-types**: Provides `RealTensor`, `ComplexTensor`, and `Complex` types

### Migration from nalgebra to faer

This crate was migrated from `nalgebra` to `faer` to achieve:
1. **WASM Compatibility**: Pure Rust implementation with no native dependencies
2. **Better Performance**: faer's modern algorithms match or exceed LAPACK performance
3. **Type Safety**: Stronger compile-time guarantees and better error handling
4. **Future-Proof**: Active development and excellent SIMD optimization

## ğŸ”Œ Used By

- **achronyme-eval**: Exposes linear algebra functions to the SOC language through the matrix function module
- **achronyme-solver**: May use matrix operations for advanced optimization algorithms
- **achronyme-numerical**: Could leverage decompositions for numerical stability

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    achronyme-linalg                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚Decompositionsâ”‚  â”‚ Eigenvalues  â”‚  â”‚   Solvers    â”‚      â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚      â”‚
â”‚  â”‚ â€¢ LU         â”‚  â”‚ â€¢ Standard   â”‚  â”‚ â€¢ Inverse    â”‚      â”‚
â”‚  â”‚ â€¢ QR         â”‚  â”‚ â€¢ Power Iter â”‚  â”‚ â€¢ Solve Ax=b â”‚      â”‚
â”‚  â”‚ â€¢ Cholesky   â”‚  â”‚ â€¢ QR Algo    â”‚  â”‚ â€¢ Determinantâ”‚      â”‚
â”‚  â”‚ â€¢ SVD        â”‚  â”‚ â€¢ Symmetric  â”‚  â”‚ â€¢ Checks     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                  â”‚                  â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                            â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Tensor Conversion Layer (RealTensor â†” faer)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            achronyme-types (RealTensor)               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            faer (Linear Algebra Engine)               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Organization

1. **decompositions.rs**: Matrix factorization algorithms (LU, QR, Cholesky, SVD)
2. **eigenvalues.rs**: Eigenvalue and eigenvector computations
3. **solvers.rs**: Linear system solving, inversion, determinants, matrix properties
4. **lib.rs**: Public API exports and module declarations

## ğŸš€ Usage Examples

### SOC Language Examples

#### Matrix Decompositions
```soc
// LU Decomposition with partial pivoting
let A = [[2, 1, 1],
         [4, 3, 3],
         [8, 7, 9]]

let result = lu(A)           // Returns {L, U, P}
let L = result.L             // Lower triangular
let U = result.U             // Upper triangular
let P = result.P             // Permutation vector
```

#### QR Decomposition
```soc
// Orthogonal-triangular factorization
let A = [[1, 1],
         [1, 2],
         [1, 3]]

let result = qr(A)           // Returns {Q, R}
let Q = result.Q             // Orthogonal matrix
let R = result.R             // Upper triangular

// Verify: A â‰ˆ Q * R
let reconstructed = Q @ R
```

#### Cholesky Decomposition
```soc
// For symmetric positive-definite matrices
let A = [[4, 2, 1],
         [2, 3, 1],
         [1, 1, 2]]

let L = cholesky(A)          // A = L * L^T
let LT = transpose(L)
let reconstructed = L @ LT    // Should equal A
```

#### Singular Value Decomposition
```soc
// SVD: A = U * Î£ * V^T
let A = [[1, 2],
         [3, 4],
         [5, 6]]

let result = svd(A)
let U = result.U              // Left singular vectors (3x2)
let S = result.S              // Singular values (vector)
let VT = result.VT            // Right singular vectors transposed (2x2)

// Reconstruct matrix
let Sigma = diag(S)           // Convert to diagonal matrix
let reconstructed = U @ Sigma @ VT
```

#### Eigenvalue Computation
```soc
// Compute eigenvalues and eigenvectors
let A = [[4, 1],
         [2, 3]]

let eigenvals = eigenvalues(A)         // Returns complex eigenvalues
let result = eigenvectors(A)           // Returns {eigenvalues, eigenvectors}

// Each column of eigenvectors is an eigenvector
let lambda1 = result.eigenvalues[0]
let v1 = result.eigenvectors[:, 0]

// Verify: A * v1 â‰ˆ lambda1 * v1
```

#### Solving Linear Systems
```soc
// Solve Ax = b
let A = [[3, 1],
         [1, 2]]
let b = [9, 8]

let x = solve(A, b)           // x = [2, 3]

// Verify solution
let b_check = A @ x           // Should equal b
```

#### Matrix Inversion
```soc
// Compute multiplicative inverse
let A = [[4, 7],
         [2, 6]]

let A_inv = inv(A)

// Verify: A * A_inv = I
let I_check = A @ A_inv       // Should be identity matrix
let det_A = det(A)            // Determinant: 10
```

#### Matrix Properties
```soc
// Check matrix characteristics
let A = [[4, 2, 1],
         [2, 3, 1],
         [1, 1, 2]]

let is_sym = is_symmetric(A, 1e-10)         // true
let is_pos_def = is_positive_definite(A)    // true (can use Cholesky)

// For non-symmetric matrix
let B = [[1, 2],
         [3, 4]]

let is_sym_B = is_symmetric(B, 1e-10)       // false
```

### Rust API Examples

#### Using Decompositions
```rust
use achronyme_linalg::{lu_decomposition, qr_decomposition, cholesky_decomposition};
use achronyme_types::tensor::RealTensor;

// LU Decomposition
let a = RealTensor::matrix(3, 3, vec![
    2.0, 1.0, 1.0,
    4.0, 3.0, 3.0,
    8.0, 7.0, 9.0
]).unwrap();

let (l, u, p) = lu_decomposition(&a).unwrap();
// l: lower triangular, u: upper triangular, p: permutation

// QR Decomposition
let a = RealTensor::matrix(3, 2, vec![
    1.0, 1.0,
    1.0, 2.0,
    1.0, 3.0
]).unwrap();

let (q, r) = qr_decomposition(&a).unwrap();
// q: orthogonal, r: upper triangular

// Cholesky Decomposition (symmetric positive-definite)
let a = RealTensor::matrix(3, 3, vec![
    4.0, 2.0, 1.0,
    2.0, 3.0, 1.0,
    1.0, 1.0, 2.0
]).unwrap();

let l = cholesky_decomposition(&a).unwrap();
// a = l * l^T
```

#### Eigenvalue Computations
```rust
use achronyme_linalg::{eigenvalues, eigenvectors, power_iteration};
use achronyme_types::tensor::RealTensor;

// Standard eigenvalue decomposition
let a = RealTensor::matrix(2, 2, vec![
    4.0, 1.0,
    2.0, 3.0
]).unwrap();

let eigs = eigenvalues(&a).unwrap();
// Returns Vec<Complex> with potentially complex eigenvalues

let (eigs, vecs) = eigenvectors(&a).unwrap();
// vecs is a matrix where each column is an eigenvector

// Power iteration for dominant eigenvalue
let (lambda, v) = power_iteration(&a, 1000, 1e-10).unwrap();
// lambda: largest eigenvalue by magnitude
// v: corresponding eigenvector
```

#### Solving Systems and Matrix Analysis
```rust
use achronyme_linalg::{solve_system, inverse, determinant_nd, is_symmetric};
use achronyme_types::tensor::RealTensor;

// Solve Ax = b
let a = RealTensor::matrix(2, 2, vec![
    3.0, 1.0,
    1.0, 2.0
]).unwrap();
let b = RealTensor::vector(vec![9.0, 8.0]);

let x = solve_system(&a, &b).unwrap();
// x = [2.0, 3.0]

// Matrix inverse
let a_inv = inverse(&a).unwrap();

// Determinant
let det = determinant_nd(&a).unwrap();

// Check properties
let is_sym = is_symmetric(&a, 1e-10);
```

## ğŸ“Š Key Algorithms Provided

### Matrix Decompositions

#### LU Decomposition with Partial Pivoting
- **Purpose**: Factorize A into lower and upper triangular matrices
- **Formula**: PÂ·A = LÂ·U
- **Complexity**: O(nÂ³)
- **Use Cases**:
  - Solving linear systems efficiently
  - Computing determinants
  - Matrix inversion
- **Algorithm**: Gaussian elimination with row pivoting
- **Stability**: Numerically stable with partial pivoting

#### QR Decomposition
- **Purpose**: Factorize A into orthogonal and upper triangular matrices
- **Formula**: A = QÂ·R
- **Complexity**: O(mnÂ²) for mÃ—n matrix (m â‰¥ n)
- **Use Cases**:
  - Least squares problems
  - Eigenvalue computation (QR algorithm)
  - Orthogonalization
- **Algorithm**: Householder reflections (in faer)
- **Stability**: Excellent numerical stability

#### Cholesky Decomposition
- **Purpose**: Factorize symmetric positive-definite matrix
- **Formula**: A = LÂ·L^T
- **Complexity**: O(nÂ³/3) - faster than LU
- **Use Cases**:
  - Efficient linear system solving for SPD matrices
  - Monte Carlo simulations
  - Optimization (Hessian matrices)
- **Algorithm**: Modified Gaussian elimination exploiting symmetry
- **Stability**: Stable for well-conditioned SPD matrices
- **Note**: Fails if matrix is not positive-definite

#### SVD (Singular Value Decomposition)
- **Purpose**: Factorize any matrix into singular values and vectors
- **Formula**: A = UÂ·Î£Â·V^T
- **Complexity**: O(min(mÂ²n, mnÂ²))
- **Use Cases**:
  - Principal Component Analysis (PCA)
  - Low-rank approximations
  - Pseudoinverse computation
  - Condition number estimation
- **Algorithm**: Two-phase approach (bidiagonalization + QR iteration)
- **Stability**: Most stable decomposition available

### Eigenvalue Algorithms

#### Standard Eigenvalue Decomposition
- **Purpose**: Find eigenvalues and eigenvectors
- **Formula**: AÂ·v = Î»Â·v
- **Complexity**: O(nÂ³)
- **Method**: QR algorithm with implicit shifts (faer implementation)
- **Output**: Complex eigenvalues (real or conjugate pairs)

#### Power Iteration
- **Purpose**: Find dominant (largest magnitude) eigenvalue
- **Complexity**: O(nÂ²) per iteration, typically converges in O(log(1/Îµ)) iterations
- **Use Cases**:
  - PageRank algorithm
  - Finding spectral radius
  - When only largest eigenvalue needed
- **Convergence**: Linear, rate depends on eigenvalue gap |Î»â‚/Î»â‚‚|

#### QR Algorithm
- **Purpose**: Compute all eigenvalues iteratively
- **Complexity**: O(nÂ³) total
- **Method**: Iterative QR decomposition: A_{k+1} = R_kÂ·Q_k
- **Convergence**: Diagonal elements converge to eigenvalues

#### Symmetric Eigenvalue Decomposition
- **Purpose**: Specialized algorithm for symmetric matrices
- **Output**: Real eigenvalues, orthogonal eigenvectors
- **Benefits**: Faster and more stable than general case
- **Future**: Will be optimized with specialized symmetric algorithms

### Linear System Solvers

#### Direct Solution (LU-based)
- **Purpose**: Solve Ax = b exactly (within numerical precision)
- **Method**: LU decomposition + forward/backward substitution
- **Complexity**: O(nÂ³) for decomposition, O(nÂ²) for substitution
- **Accuracy**: Limited by machine precision and condition number

#### Matrix Inverse
- **Purpose**: Compute A^(-1)
- **Method**: Solve AÂ·X = I using LU decomposition
- **Complexity**: O(nÂ³)
- **Note**: Direct solving Ax = b is often more efficient than computing A^(-1)Â·b

#### Determinant Computation
- **Purpose**: Compute det(A)
- **Method**: LU decomposition + product of diagonal elements
- **Complexity**: O(nÂ³)
- **Sign**: Adjusted for permutation parity

## ğŸ”¬ Mathematical Foundations

### Matrix Theory Concepts

#### Vector Spaces and Linear Independence
- **Span**: Set of all linear combinations of vectors
- **Basis**: Linearly independent set that spans the space
- **Dimension**: Number of vectors in a basis
- **Rank**: Dimension of column space = dimension of row space

#### Matrix Norms and Conditioning
- **Frobenius Norm**: ||A||_F = âˆš(Î£ a_{ij}Â²)
- **Spectral Norm**: ||A||_2 = largest singular value
- **Condition Number**: Îº(A) = ||A|| Â· ||A^(-1)||
  - Well-conditioned: Îº(A) â‰ˆ 1
  - Ill-conditioned: Îº(A) >> 1
  - Singular: Îº(A) = âˆ

#### Matrix Properties
- **Symmetric**: A = A^T
- **Orthogonal**: Q^TÂ·Q = I (preserves norms and angles)
- **Positive Definite**: x^TÂ·AÂ·x > 0 for all x â‰  0
  - All eigenvalues positive
  - Admits Cholesky decomposition
- **Hermitian**: A = Ä€^T (complex analog of symmetric)

### Numerical Stability Considerations

#### Sources of Numerical Error
1. **Rounding Error**: Limited precision (machine epsilon â‰ˆ 2.22Ã—10^(-16) for f64)
2. **Cancellation**: Subtraction of nearly equal numbers
3. **Overflow/Underflow**: Values outside representable range
4. **Accumulation**: Error growth through iterative algorithms

#### Stability Strategies
1. **Pivoting**: Swap rows/columns to avoid small pivot elements
   - Partial pivoting: O(nÂ²) overhead, good practical stability
   - Full pivoting: O(nÂ³) overhead, theoretical stability
2. **Orthogonal Transformations**: Preserve norms (QR, Householder)
3. **Scaling**: Normalize matrices to improve conditioning
4. **Iterative Refinement**: Improve solution accuracy post-computation

#### Algorithm Stability Rankings
1. **Most Stable**: SVD, QR decomposition
2. **Stable with Pivoting**: LU with partial pivoting
3. **Conditionally Stable**: Cholesky (requires SPD matrix)
4. **Potentially Unstable**: Direct Gaussian elimination (no pivoting)

### Complexity Analysis

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| Matrix Multiplication (nÃ—n) | O(nÂ³) | Can be reduced to ~O(n^2.37) with Strassen |
| LU Decomposition | O(nÂ³) | 2nÂ³/3 flops |
| QR Decomposition | O(nÂ³) | 2nÂ³ flops for square matrices |
| Cholesky Decomposition | O(nÂ³/3) | nÂ³/3 flops (half of LU) |
| SVD | O(nÂ³) | ~11nÂ³ flops |
| Eigenvalue (general) | O(nÂ³) | Iterative, depends on spectrum |
| Forward/Backward Substitution | O(nÂ²) | |
| Matrix Inverse | O(nÂ³) | Same as LU decomposition |
| Determinant | O(nÂ³) | Via LU decomposition |

### When to Use Each Decomposition

```
Decomposition Selection Guide
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Problem: Solve Ax = b
â”œâ”€ A is symmetric positive definite â†’ Cholesky
â”œâ”€ A is symmetric â†’ LU with symmetric pivoting
â”œâ”€ Need to solve for multiple b â†’ LU (reuse decomposition)
â””â”€ General case â†’ LU with partial pivoting

Problem: Least Squares (minimize ||Ax - b||)
â””â”€ QR decomposition or SVD

Problem: Eigenvalues/Eigenvectors
â”œâ”€ Only dominant eigenvalue â†’ Power Iteration
â”œâ”€ Symmetric matrix â†’ Symmetric eigendecomposition
â””â”€ General matrix â†’ Standard eigendecomposition

Problem: Matrix Rank/Nullspace
â””â”€ SVD (most reliable)

Problem: Condition Number
â””â”€ SVD (Ïƒ_max / Ïƒ_min)

Problem: Low-rank Approximation
â””â”€ SVD truncation

Problem: Orthogonalization
â””â”€ QR decomposition
```

## ğŸ§ª Testing

### Run All Tests
```bash
cargo test -p achronyme-linalg
```

### Run with Output
```bash
cargo test -p achronyme-linalg -- --nocapture
```

### Test Specific Module
```bash
cargo test -p achronyme-linalg --lib decompositions
cargo test -p achronyme-linalg --lib eigenvalues
cargo test -p achronyme-linalg --lib solvers
```

### Test Coverage
The test suite includes:
- Basic functionality tests for each algorithm
- Edge cases (singular matrices, non-square matrices, etc.)
- Numerical accuracy verification using `approx` crate
- Reconstruction tests (verifying A = LÂ·U, A = QÂ·R, etc.)
- Error handling (invalid inputs, dimension mismatches)

## ğŸ“ˆ Performance Characteristics

### faer vs nalgebra vs LAPACK
The `faer` library provides:
- **Competitive Performance**: Matches or exceeds LAPACK for many operations
- **Better SIMD Utilization**: Modern vectorization strategies
- **Zero-Cost Abstractions**: No runtime overhead from Rust abstractions
- **WASM Compatibility**: Works in browser environments (unlike LAPACK bindings)

### Optimization Tips
1. **Reuse Decompositions**: If solving Ax = b for multiple b, compute LU once
2. **Choose Right Algorithm**: Cholesky is 2Ã— faster than LU for SPD matrices
3. **Avoid Unnecessary Inversions**: Solve Ax = b directly instead of x = A^(-1)Â·b
4. **Consider Sparsity**: faer has sparse matrix support (not yet exposed in achronyme-linalg)
5. **Batch Operations**: Process multiple matrices together when possible

### Memory Usage
| Operation | Memory Overhead | Notes |
|-----------|----------------|-------|
| LU Decomposition | O(nÂ²) | Stores L and U |
| QR Decomposition | O(nÂ²) | Stores Q and R |
| SVD | O(nÂ²) | Stores U, Î£, V^T |
| Eigendecomposition | O(nÂ²) | Stores eigenvalues + eigenvectors |
| In-place Operations | O(1) | faer supports some in-place ops |

## ğŸ”— Related Crates

- **achronyme-types**: Core tensor and complex number types
- **achronyme-eval**: Evaluator that exposes linalg functions to SOC
- **achronyme-solver**: Optimization algorithms (may use linalg internally)
- **achronyme-numerical**: Numerical methods (differentiation, integration)
- **achronyme-dsp**: Digital signal processing (FFT, convolution)

## ğŸ“š References

### Textbooks
1. **Golub & Van Loan**: "Matrix Computations" (4th ed.) - The definitive reference
2. **Trefethen & Bau**: "Numerical Linear Algebra" - Excellent for understanding stability
3. **Demmel**: "Applied Numerical Linear Algebra" - Comprehensive modern treatment
4. **Horn & Johnson**: "Matrix Analysis" - Deep theoretical treatment

### Papers and Resources
- Higham, N. J.: "Accuracy and Stability of Numerical Algorithms"
- Wilkinson, J. H.: "The Algebraic Eigenvalue Problem"
- LAPACK documentation: https://netlib.org/lapack/
- faer documentation: https://docs.rs/faer/

### Online Resources
- Matrix Cookbook: https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
- Numerical Linear Algebra course notes (Trefethen): https://people.maths.ox.ac.uk/trefethen/

## ğŸ“ Educational Notes

### Understanding Matrix Decompositions

**Why decompose matrices?**
1. **Numerical Stability**: Well-conditioned subproblems
2. **Efficiency**: Solve related problems faster
3. **Insight**: Reveal structure (rank, conditioning, eigenvalues)
4. **Generality**: Handle edge cases (singular, rectangular matrices)

**Visual Intuition**:
```
LU Decomposition:
    â”Œ     â”       â”Œ     â”   â”Œ     â”
    â”‚ a b â”‚   =   â”‚ 1 0 â”‚ Ã— â”‚ u v â”‚
    â”‚ c d â”‚       â”‚ l 1 â”‚   â”‚ 0 w â”‚
    â””     â”˜       â””     â”˜   â””     â”˜
     Original      Lower     Upper

QR Decomposition:
    â”Œ     â”       â”Œ     â”   â”Œ     â”
    â”‚ â†’  â”‚   =   â”‚ â†‘ â†‘ â”‚ Ã— â”‚ â•²   â”‚
    â”‚ â†’  â”‚       â”‚ â†‘ â†‘ â”‚   â”‚   â•² â”‚
    â”‚ â†’  â”‚       â”‚ â†‘ â†‘ â”‚   â””     â”˜
    â””     â”˜       â””     â”˜   Triangular
     Original    Orthogonal

SVD:
    â”Œ     â”       â”Œ     â”   â”Œ   â”   â”Œ     â”
    â”‚ â†’  â”‚   =   â”‚ â†‘ â†‘ â”‚ Ã— â”‚ Ïƒ â”‚ Ã— â”‚ â†” â†” â”‚
    â”‚ â†’  â”‚       â”‚ â†‘ â†‘ â”‚   â””   â”˜   â””     â”˜
    â”‚ â†’  â”‚       â”‚ â†‘ â†‘ â”‚   Singular   Right
    â””     â”˜       â””     â”˜   Values    Vectors
     Original     Left
                 Vectors
```

### Common Pitfalls and Solutions

1. **Computing A^(-1) explicitly**
   - âŒ Bad: `x = inv(A) @ b`
   - âœ… Good: `x = solve(A, b)`
   - Why: Solving directly is faster and more accurate

2. **Using wrong decomposition**
   - âŒ Bad: SVD for solving well-conditioned square systems
   - âœ… Good: LU for general, Cholesky for SPD matrices
   - Why: SVD is slower, use it when you need its special properties

3. **Ignoring condition number**
   - âŒ Bad: Trusting results without checking Îº(A)
   - âœ… Good: Estimate condition number, use regularization if needed
   - Why: Ill-conditioned matrices amplify errors exponentially

4. **Not checking matrix properties**
   - âŒ Bad: Assuming matrix is invertible
   - âœ… Good: Check determinant â‰  0 or handle errors gracefully
   - Why: Singular matrices cause division by zero

## ğŸš§ Future Enhancements

### Planned Features
- [ ] Sparse matrix support (CSR/CSC formats)
- [ ] Iterative solvers (Conjugate Gradient, GMRES)
- [ ] Parallel matrix operations
- [ ] Complex matrix eigendecomposition
- [ ] Generalized eigenvalue problems (Ax = Î»Bx)
- [ ] Matrix exponential and logarithm
- [ ] Schur decomposition
- [ ] Hessenberg reduction

### Performance Improvements
- [ ] Cache-friendly memory layouts
- [ ] Explicit SIMD optimizations
- [ ] GPU acceleration (via wgpu)
- [ ] Multi-threaded decompositions

### API Enhancements
- [ ] Builder patterns for fine-tuned algorithms
- [ ] Streaming/incremental decompositions
- [ ] Better error messages with recovery suggestions
- [ ] Integration with automatic differentiation

---

**Version**: 0.1.0
**License**: Same as Achronyme project
**Maintainer**: Achronyme Project Team
